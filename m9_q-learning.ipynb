{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-learning is a model-free, off-policy, value-based reinforcement learning algorithm that aims to find the best series of actions based on the agent's current state.\n",
    "\n",
    "- **model-free**: Learning from experience, no transition and reward function.\n",
    "- **off-policy**: Learning from actions that are coutside the current policy, e.g., by taking random actions.\n",
    "- **value-based**: Training the value function to learn which state is more valuable for taking action.\n",
    "\n",
    "#### Q-function\n",
    "In Q-learning, we keep a function called Q-function for choosing our next action in our current state. Therefore, it accepts the current state and current action as its parameters. You can think of the Q-function as a diary of the agent which keeps track of what rewards it collected in the past after choosing actions in different states.\n",
    "\n",
    "![Q-function (source: Freecodecamp)](qfunction.png) (Source: Freecodecamp)\n",
    "\n",
    "At the beginning, the Q-function is initialized **randomly** or based on a heuristic. The learning consists of multiple episodes and a new episode is created after the old one reached a terminal state and the Q-function has not converged yet.\n",
    "\n",
    "In each episode, at each state, the agent chooses an action based on some policy. This policy is usually obtained using a simple method called **epsilon-greedy**, which balances **exploration** and **exploitation** by choosing betweenthem randomly. After taking the action and getting an immediate reward, the agent updates the Q-learning entry. The learning rate and discount factor determines to what extent newly acquired information overrides old information and the importance of future rewards, respectively.\n",
    "\n",
    "#### Q-table\n",
    "A Q-table is a table of rewards associated with optimal actions for each state in a given environment. It serves as a guide for the agent, helping to determine which actions are likely to yield the best outcomes. The Q-table initialized to zero and then dynamically updated during training to reflect the agentâ€™s evolving understanding, enabling more informed decision-making.\n",
    "\n",
    "<img alt=\"Q-table (source: Wikipedia)]\" src=\"qtable.png\" width=500> (Source: Wikipedia)\n",
    "\n",
    "**Summary of steps of the Q-learning algorithm**:\n",
    "1. Initialize a Q-table\n",
    "2. Choose an action\n",
    "3. Perform the action\n",
    "4. Measure reward\n",
    "5. Update the Q-table\n",
    "6. Repeat from step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup virtual display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pyglet==1.5.1 \n",
    "!apt install python-opengl\n",
    "!apt install ffmpeg\n",
    "!apt install xvfb\n",
    "!pip install pyvirtualdisplay\n",
    "from ipywidgets import FloatProgress\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gym==0.23\n",
    "!pip install pygame\n",
    "!pip install numpy\n",
    "!pip install imageio imageio_ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Set up environment, sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the FrozenLake-v1 environment using a 4x4 map and non-slippery version\n",
    "env = gym.make(\"FrozenLake-v1\",map_name=\"4x4\",is_slippery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "Observation Space Discrete(16)\n",
      "Sample observation 2\n"
     ]
    }
   ],
   "source": [
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space\", env.observation_space)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "Action Space Shape 4\n",
      "Action Space Sample 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create and initialize Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  16  possible states\n",
      "There are  4  possible actions\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")\n",
    "\n",
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Q-table of size (state_space, action_space) and initialize each values at 0 using np.zeros\n",
    "def initialize_q_table(state_space, action_space):\n",
    "    Qtable = np.zeros((state_space, action_space))\n",
    "    return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Define policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "    random_int = random.uniform(0,1)\n",
    "    # if random_int > greater than epsilon -> exploitation\n",
    "    if random_int > epsilon:\n",
    "    # take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "        action = np.argmax(Qtable[state])\n",
    "    # else -> exploration\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "  \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(Qtable, state):\n",
    "    # exploitation: take the action with the highest state, action value\n",
    "    action = np.argmax(Qtable[state])\n",
    "  \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_episodes = 10000  # Total number of training episodes\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"FrozenLake-v1\"     # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "eval_seed = []               # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0            # Exploration probability at start\n",
    "min_epsilon = 0.05           # Minimum exploration probability \n",
    "decay_rate = 0.0005          # Exponential decay rate for exploration probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "    for episode in trange(n_training_episodes):\n",
    "        # reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        # reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "\n",
    "        # repeat\n",
    "        for step in range(max_steps):\n",
    "            # choose the action using epsilon greedy policy\n",
    "            action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "\n",
    "            # take action At and observe Rt+1 and St+1\n",
    "            # take action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action]) \n",
    "\n",
    "            # if done, finish the episode\n",
    "            if done:\n",
    "                break\n",
    "      \n",
    "            # our state is the new state\n",
    "            state = new_state\n",
    "    return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb881ef7a2a425b9b923609260e2884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n",
       "       [0.73509189, 0.        , 0.81450625, 0.77378094],\n",
       "       [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n",
       "       [0.81450625, 0.        , 0.77378086, 0.77378094],\n",
       "       [0.77378094, 0.81450625, 0.        , 0.73509189],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.        , 0.81450625],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.81450625, 0.        , 0.857375  , 0.77378094],\n",
       "       [0.81450625, 0.9025    , 0.9025    , 0.        ],\n",
       "       [0.857375  , 0.95      , 0.        , 0.857375  ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.95      , 0.857375  ],\n",
       "       [0.9025    , 0.95      , 1.        , 0.9025    ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained q-learning table\n",
    "\n",
    "Qtable_frozenlake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "    \"\"\"\n",
    "    Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "    :param env: The evaluation environment\n",
    "    :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "    :param Q: The Q-table\n",
    "    :param seed: The evaluation seed array (for taxi-v3)\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    for episode in range(n_eval_episodes):\n",
    "        if seed:\n",
    "            state = env.reset(seed=seed[episode])\n",
    "        else:\n",
    "            state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards_ep = 0\n",
    "    \n",
    "        for step in range(max_steps):\n",
    "            # take the action (index) with the maximum expected future reward given that state\n",
    "            action = np.argmax(Q[state][:])\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            total_rewards_ep += reward\n",
    "        \n",
    "            if done:\n",
    "                break\n",
    "            state = new_state\n",
    "        episode_rewards.append(total_rewards_ep)\n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "\n",
    "    return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_reward=1.00 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(env, Qtable, out_directory, fps=1):\n",
    "    images = []  \n",
    "    done = False\n",
    "    state = env.reset(seed=random.randint(0,500))\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "    while not done:\n",
    "    # take the action (index) that have the maximum expected future reward given that state\n",
    "        action = np.argmax(Qtable[state][:])\n",
    "        state, reward, done, info = env.step(action) # next_state = state for recording logic\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(img)\n",
    "    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=\"content/replay.gif\"\n",
    "duration=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_video(env, Qtable_frozenlake, video_path, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('content/replay.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Questions\n",
    "- What happens if you change the environment size (e.g., 8x8)?\n",
    "- What happens if you change any of the hyperparameters? Which are helpful to tune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frozenlake",
   "language": "python",
   "name": "frozenlake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
